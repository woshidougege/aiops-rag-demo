"""
AIOps RAG Demo - LangChain æ¡†æ¶ç‰ˆæœ¬
"""

from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from typing import Optional, List, Dict
import uvicorn
import os
import json

# LangChain æ ¸å¿ƒç»„ä»¶
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

from config import LLM_CONFIG, EMBEDDING_CONFIG, MILVUS_CONFIG, RERANKER_CONFIG


# ===================================================================
# åˆå§‹åŒ–
# ===================================================================
app = FastAPI(
    title="AIOps RAG Demo",
    description="æ™ºèƒ½è¿ç»´æ•…éšœè¯Šæ–­ç³»ç»Ÿ",
    version="1.0.0"
)

print("ğŸš€ å¯åŠ¨ AIOps RAG Demo...")


# ===================================================================
# Reranker ç²¾æ’å™¨
# ===================================================================
class SiliconFlowReranker:
    """SiliconFlow API çš„ Reranker"""
    
    def __init__(self):
        self.api_url = RERANKER_CONFIG['api_url']
        self.api_key = RERANKER_CONFIG['api_key']
        self.model = RERANKER_CONFIG['model']
        self.top_n = RERANKER_CONFIG['top_n']
    
    def rerank(self, query: str, documents: List[Dict]) -> List[Dict]:
        """å¯¹æ£€ç´¢ç»“æœè¿›è¡Œç²¾æ’"""
        if not documents:
            return documents
        
        try:
            import requests
            # å‡†å¤‡æ–‡æ¡£æ–‡æœ¬
            texts = [doc.get('content', '') or f"{doc.get('error_type', '')} {doc.get('root_cause', '')}" 
                    for doc in documents]
            
            # è°ƒç”¨ Reranker API
            response = requests.post(
                self.api_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "query": query,
                    "documents": texts,
                    "top_n": self.top_n
                },
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                # æ ¹æ® Reranker è¿”å›çš„ç´¢å¼•é‡æ–°æ’åº
                reranked = []
                for item in result.get('results', [])[:self.top_n]:
                    idx = item['index']
                    doc = documents[idx].copy()
                    doc['rerank_score'] = item['relevance_score']
                    reranked.append(doc)
                print(f"  âœ“ Reranker ç²¾æ’å®Œæˆï¼Œè¿”å› Top-{len(reranked)}")
                return reranked
            else:
                print(f"  âš  Reranker è°ƒç”¨å¤±è´¥: {response.status_code}")
                return documents[:self.top_n]
        
        except Exception as e:
            print(f"  âš  Reranker å¼‚å¸¸: {e}")
            return documents[:self.top_n]


# ===================================================================
# RAGå¼•æ“ï¼ˆLangChain å®Œæ•´ç‰ˆï¼šLLM + Embedding + Reranker + Milvusï¼‰
# ===================================================================
class LangChainRAGEngine:
    """åŸºäº LangChain çš„ RAG å¼•æ“"""
    
    def __init__(self):
        print("ğŸš€ åˆå§‹åŒ– LangChain RAG å¼•æ“...")
        
        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            base_url=LLM_CONFIG['api_base'],
            api_key=LLM_CONFIG['api_key'],
            model=LLM_CONFIG['model'],
            temperature=LLM_CONFIG['temperature'],
            max_tokens=LLM_CONFIG['max_tokens']
        )
        print(f"âœ“ LLM å·²åˆå§‹åŒ–: {LLM_CONFIG['model']}")
        
        # åˆå§‹åŒ– Embeddings
        self.embeddings = OpenAIEmbeddings(
            base_url=EMBEDDING_CONFIG['api_url'].replace('/embeddings', ''),
            api_key=EMBEDDING_CONFIG['api_key'],
            model=EMBEDDING_CONFIG['model']
        )
        print(f"âœ“ Embedding å·²åˆå§‹åŒ–: {EMBEDDING_CONFIG['model']}")
        
        # åˆå§‹åŒ– Rerankerï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if RERANKER_CONFIG.get('enabled', False):
            self.reranker = SiliconFlowReranker()
            print(f"âœ“ Reranker å·²åˆå§‹åŒ–: {RERANKER_CONFIG['model']}")
        else:
            self.reranker = None
            print("âš  Reranker æœªå¯ç”¨")
        
        # åŠ è½½çŸ¥è¯†åº“å¹¶åˆå§‹åŒ–å‘é‡å­˜å‚¨
        self.vectorstore = None
        self.knowledge_base = []
        self.load_knowledge()
        
        # åˆ›å»ºè¯Šæ–­æç¤ºæ¨¡æ¿
        self.diagnosis_prompt = ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ AIOps è¿ç»´ä¸“å®¶ï¼Œæ“…é•¿åˆ†æç³»ç»Ÿæ•…éšœå¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚"),
            ("user", """è¯·åˆ†æä»¥ä¸‹æ•…éšœå¹¶ä»¥JSONæ ¼å¼è¾“å‡ºè¯Šæ–­ç»“æœã€‚

ã€å½“å‰æ•…éšœã€‘
{error_log}

ã€å†å²ç›¸ä¼¼æ¡ˆä¾‹ã€‘
{retrieved_cases}

ã€è¾“å‡ºè¦æ±‚ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
  "diagnosis": "æ•…éšœè¯Šæ–­ï¼ˆä¸€å¥è¯æ¦‚æ‹¬ï¼‰",
  "root_cause": "æ ¹æœ¬åŸå› åˆ†æï¼ˆæ·±å…¥æŠ€æœ¯ç»†èŠ‚ï¼‰",
  "solution": "è§£å†³æ–¹æ¡ˆï¼ˆåˆ†æ­¥éª¤ï¼Œå¯æ‰§è¡Œï¼‰",
  "confidence": 0.85
}}""")
        ])
        
        # åˆ›å»ºè¯Šæ–­é“¾
        self.diagnosis_chain = (
            self.diagnosis_prompt 
            | self.llm 
            | StrOutputParser()
        )
        
        print("âœ“ RAG å¼•æ“åˆå§‹åŒ–å®Œæˆ\n")
    
    def load_knowledge(self):
        """åŠ è½½çŸ¥è¯†åº“åˆ°å‘é‡å­˜å‚¨"""
        kb_path = "data/knowledge_base.json"
        if os.path.exists(kb_path):
            with open(kb_path, 'r', encoding='utf-8') as f:
                self.knowledge_base = json.load(f)
            print(f"âœ“ åŠ è½½äº† {len(self.knowledge_base)} æ¡çŸ¥è¯†æ¡ˆä¾‹")
            
            # è½¬æ¢ä¸º LangChain Documents
            documents = []
            for case in self.knowledge_base:
                content = f"""é”™è¯¯ç±»å‹: {case['error_type']}
æ—¥å¿—å†…å®¹: {case.get('log_content', '')}
æ ¹æœ¬åŸå› : {case['root_cause']}
è§£å†³æ–¹æ¡ˆ: {case['solution']}"""
                
                metadata = {
                    "error_type": case['error_type'],
                    "root_cause": case['root_cause'],
                    "solution": case['solution'],
                    "severity": case.get('severity', 'medium')
                }
                documents.append(Document(page_content=content, metadata=metadata))
            
            # ä¼˜å…ˆä½¿ç”¨ Milvusï¼Œå¤±è´¥åˆ™é™çº§åˆ° FAISS
            try:
                from langchain_milvus import Milvus
                from pymilvus import connections
                
                print(f"ğŸ”„ å°è¯•è¿æ¥ Milvus: {MILVUS_CONFIG['host']}:{MILVUS_CONFIG['port']}...")
                
                # å…ˆå»ºç«‹è¿æ¥
                connections.connect(
                    alias="default",
                    host=MILVUS_CONFIG['host'],
                    port=int(MILVUS_CONFIG['port']),
                    timeout=10
                )
                print("  âœ“ Milvus è¿æ¥æˆåŠŸ")
                
                # åˆ›å»ºå‘é‡å­˜å‚¨
                self.vectorstore = Milvus.from_documents(
                    documents,
                    self.embeddings,
                    collection_name=MILVUS_CONFIG['collection_name'],
                    connection_args={"alias": "default"},
                    drop_old=True  # é‡æ–°åˆ›å»ºcollection
                )
                print(f"âœ“ å‘é‡å­˜å‚¨å·²åˆ›å»ºï¼ˆä½¿ç”¨ Milvus: {MILVUS_CONFIG['host']}:{MILVUS_CONFIG['port']}ï¼‰")
            except Exception as e:
                print(f"âš  Milvus è¿æ¥å¤±è´¥: {e}")
                print("ğŸ”„ é™çº§ä½¿ç”¨ FAISS...")
                try:
                    self.vectorstore = FAISS.from_documents(documents, self.embeddings)
                    print("âœ“ å‘é‡å­˜å‚¨å·²åˆ›å»ºï¼ˆä½¿ç”¨ FAISS æœ¬åœ°å­˜å‚¨ï¼‰")
                except Exception as e2:
                    print(f"âš  FAISS åˆ›å»ºå¤±è´¥: {e2}")
                    self.vectorstore = None
        else:
            print(f"âš  çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {kb_path}")
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """æ£€ç´¢ç›¸ä¼¼æ¡ˆä¾‹"""
        print(f"ğŸ” æ£€ç´¢: {query[:50]}...")
        
        if not self.vectorstore:
            print("âš  å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ç®€å•åŒ¹é…")
            return self.simple_search(query, top_k)
        
        try:
            # ä½¿ç”¨ LangChain çš„ç›¸ä¼¼åº¦æœç´¢
            docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=top_k)
            
            results = []
            for doc, score in docs_with_scores:
                # è½¬æ¢åˆ†æ•°ä¸ºç›¸ä¼¼åº¦ (FAISS è¿”å›çš„æ˜¯è·ç¦»ï¼Œè¶Šå°è¶Šç›¸ä¼¼)
                similarity = 1.0 / (1.0 + score)
                results.append({
                    "error_type": doc.metadata.get('error_type', 'æœªçŸ¥'),
                    "root_cause": doc.metadata.get('root_cause', ''),
                    "solution": doc.metadata.get('solution', ''),
                    "severity": doc.metadata.get('severity', 'medium'),
                    "similarity": round(similarity, 3),
                    "content": doc.page_content
                })
            
            print(f"âœ“ å‘é‡æ£€ç´¢æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼æ¡ˆä¾‹")
            
            # ä½¿ç”¨ Reranker ç²¾æ’ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.reranker and RERANKER_CONFIG.get('enabled', False):
                print("ğŸ”„ ä½¿ç”¨ Reranker è¿›è¡Œç²¾æ’...")
                results = self.reranker.rerank(query, results)
            
            return results
            
        except Exception as e:
            print(f"âš  å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return self.simple_search(query, top_k)
    
    def simple_search(self, query: str, top_k: int = 3) -> List[Dict]:
        """ç®€å•çš„å…³é”®è¯åŒ¹é…æœç´¢ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        results = []
        query_lower = query.lower()
        
        for case in self.knowledge_base:
            case_text = f"{case['error_type']} {case.get('log_content', '')} {case['root_cause']}".lower()
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            common_words = set(query_lower.split()) & set(case_text.split())
            similarity = len(common_words) / max(len(query_lower.split()), 1)
            
            if similarity > 0:
                results.append({
                    **case,
                    "similarity": round(similarity, 3)
                })
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:top_k]
    
    def diagnose(self, error_log: str) -> Dict:
        """å®Œæ•´è¯Šæ–­æµç¨‹"""
        print("ğŸ”® å¼€å§‹è¯Šæ–­...")
        
        # 1. RAG æ£€ç´¢ç›¸ä¼¼æ¡ˆä¾‹
        cases = self.search(error_log, top_k=3)
        
        # 2. æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
        if cases:
            history_text = ""
            for i, case in enumerate(cases, 1):
                history_text += f"\næ¡ˆä¾‹{i}ï¼ˆç›¸ä¼¼åº¦: {case.get('similarity', 0):.2f}ï¼‰:\n"
                history_text += f"  é”™è¯¯ç±»å‹: {case['error_type']}\n"
                history_text += f"  æ ¹æœ¬åŸå› : {case['root_cause']}\n"
                history_text += f"  è§£å†³æ–¹æ¡ˆ: {case['solution']}\n"
        else:
            history_text = "æ— ç›¸ä¼¼å†å²æ¡ˆä¾‹"
        
        # 3. ä½¿ç”¨ LangChain é“¾è¿›è¡Œè¯Šæ–­
        try:
            print("ğŸ¤– è°ƒç”¨ LLM ç”Ÿæˆè¯Šæ–­...")
            response = self.diagnosis_chain.invoke({
                "error_log": error_log,
                "retrieved_cases": history_text
            })
            
            print(f"ğŸ“ [DEBUG] LLM åŸå§‹å“åº”:\n{response[:500]}...")  # åªæ‰“å°å‰500å­—ç¬¦
            
            # 4. è§£æ JSON ç»“æœ
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
            else:
                result = json.loads(response)
            
            print(f"ğŸ“ [DEBUG] è§£æåçš„ç»“æœ: {result}")
            print(f"ğŸ“ [DEBUG] confidence å­—æ®µ: {result.get('confidence')} (ç±»å‹: {type(result.get('confidence'))})")
            
            result['retrieved_cases'] = cases
            print("âœ“ è¯Šæ–­å®Œæˆ")
            return result
            
        except Exception as e:
            print(f"âš  LLM è°ƒç”¨å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªç›¸ä¼¼æ¡ˆä¾‹
            if cases:
                return {
                    "diagnosis": f"åŸºäºå†å²æ¡ˆä¾‹çš„è¯Šæ–­ï¼š{cases[0]['error_type']}",
                    "root_cause": cases[0]['root_cause'],
                    "solution": cases[0]['solution'],
                    "confidence": cases[0].get('similarity', 0.5),
                    "retrieved_cases": cases
                }
            else:
                return {
                    "diagnosis": "æ— æ³•è‡ªåŠ¨è¯Šæ–­",
                    "root_cause": "æœªæ‰¾åˆ°ç›¸ä¼¼æ¡ˆä¾‹ï¼Œå»ºè®®äººå·¥æ’æŸ¥",
                    "solution": "è¯·æä¾›æ›´å¤šæ—¥å¿—ä¿¡æ¯æˆ–è”ç³»è¿ç»´å›¢é˜Ÿ",
                    "confidence": 0.0,
                    "retrieved_cases": []
                }


# åˆå§‹åŒ–RAGå¼•æ“
rag_engine = LangChainRAGEngine()


# ===================================================================
# æ•°æ®æ¨¡å‹
# ===================================================================
class DiagnosisRequest(BaseModel):
    error_log: str
    top_k: Optional[int] = 3


class DiagnosisResponse(BaseModel):
    success: bool
    diagnosis: str
    root_cause: str
    solution: str
    confidence: float
    retrieved_cases: list


# ===================================================================
# APIè·¯ç”±
# ===================================================================
@app.get("/", response_class=HTMLResponse)
async def index():
    """ä¸»é¡µ"""
    html_path = "templates/index.html"
    if os.path.exists(html_path):
        with open(html_path, 'r', encoding='utf-8') as f:
            return HTMLResponse(content=f.read())
    return HTMLResponse("<h1>AIOps RAG Demo</h1><p><a href='/docs'>APIæ–‡æ¡£</a></p>")


@app.get("/health")
async def health():
    return {"status": "healthy", "knowledge_base": len(rag_engine.knowledge_base)}


@app.post("/api/diagnose", response_model=DiagnosisResponse)
async def diagnose(request: DiagnosisRequest):
    """è¯Šæ–­API"""
    try:
        result = rag_engine.diagnose(request.error_log)
        
        print(f"ğŸ“ [DEBUG] RAGå¼•æ“è¿”å›çš„ç»“æœ: {result}")
        print(f"ğŸ“ [DEBUG] retrieved_cases æ•°é‡: {len(result.get('retrieved_cases', []))}")
        
        # å®‰å…¨åœ°è½¬æ¢ confidence
        raw_confidence = result.get('confidence', 0.5)
        try:
            confidence_value = float(raw_confidence)
        except (ValueError, TypeError) as e:
            print(f"âš  [DEBUG] confidence è½¬æ¢å¤±è´¥: {raw_confidence}, é”™è¯¯: {e}")
            confidence_value = 0.5
        
        print(f"ğŸ“ [DEBUG] confidence æœ€ç»ˆå€¼: {confidence_value}")
        
        # å®‰å…¨åœ°å¤„ç† retrieved_cases
        safe_cases = []
        for i, c in enumerate(result.get('retrieved_cases', [])):
            print(f"ğŸ“ [DEBUG] å¤„ç†æ¡ˆä¾‹ {i}: {c}")
            safe_cases.append({
                "error_type": c.get('error_type', 'æœªçŸ¥'),
                "similarity": float(c.get('similarity', 0)),
                "root_cause": c.get('root_cause', ''),
                "solution": c.get('solution', '')
            })
        
        # å¤„ç† solution å­—æ®µï¼šå¯èƒ½æ˜¯ list æˆ– str
        raw_solution = result.get('solution', '')
        if isinstance(raw_solution, list):
            solution_str = '\n'.join(str(s) for s in raw_solution)
        else:
            solution_str = str(raw_solution)
        
        response = DiagnosisResponse(
            success=True,
            diagnosis=result.get('diagnosis', ''),
            root_cause=result.get('root_cause', ''),
            solution=solution_str,
            confidence=confidence_value,
            retrieved_cases=safe_cases
        )
        
        print("âœ… [DEBUG] DiagnosisResponse æ„é€ æˆåŠŸ")
        return response
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"âŒ [DEBUG] API å¼‚å¸¸:\n{error_detail}")
        raise HTTPException(status_code=500, detail=str(e))


# ===================================================================
# å¯åŠ¨
# ===================================================================
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:8888")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8888/docs")
    print("="*60 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8888, log_level="info")
