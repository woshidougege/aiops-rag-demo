# AIOps 智能运维系统 - 需求文档

## 📋 项目概述

### 项目名称
AIOps 智能运维故障诊断系统（基于RAG + 本地大模型）

### 项目背景
随着微服务架构和云原生技术的普及，运维复杂度急剧上升。传统的人工排查故障效率低下，平均MTTR（故障恢复时间）达2小时以上。本项目旨在通过AI技术实现故障的智能检测、诊断和自动修复，将MTTR降低到10分钟以内，降低92%。

### 核心目标
1. **智能检测**：实时监控指标和日志，30秒内发现异常
2. **智能诊断**：基于RAG检索历史案例，使用大模型生成诊断报告
3. **智能修复**：60%的故障自动修复，40%提供修复建议
4. **知识沉淀**：每次故障处理后自动归档，形成知识库

---

## 🎯 核心功能需求

### 1. 故障检测（Detection）

#### 1.1 指标异常检测
**输入**：
- 时序指标数据（CPU、内存、磁盘、网络、JVM、数据库等）
- 采集频率：15秒/次
- 数据量：3000+指标，每分钟1.2万条数据

**处理逻辑**：
- **3-Sigma规则**：适用于平稳指标（CPU/内存）
  - 计算过去7天同时段均值μ和标准差σ
  - 当前值 |x-μ| > 3σ 则报警
- **动态基线**：对比过去7天同时段均值，避免业务高峰误报
- **连续异常判定**：连续3次异常才触发告警（降低噪音）
- **时序预测（LSTM/Prophet）**：
  - 预测未来5-30分钟趋势
  - 提前告警（如预测10分钟后CPU>90%）

**输出**：
- 异常告警（包含：异常指标、当前值、阈值、持续时间）
- 预测趋势图

#### 1.2 日志异常检测
**输入**：
- 应用日志（日均1TB+，500台服务器 × 2GB/天）
- 日志格式：ERROR/WARN/INFO级别

**处理逻辑**：
1. **日志解析（Drain算法）**：
   - 自动提取日志模板（10万条 → 200个模板）
   - 识别变量部分（如用户ID、IP地址）
2. **日志聚类（DBSCAN）**：
   - TF-IDF向量化日志
   - 自动分组相似日志
   - 噪声点即为异常日志
3. **错误日志分类（BERT）**：
   - 微调BERT-base-chinese
   - 分类10种故障类型：OOM、超时、权限、网络、数据库等
   - 准确率目标：>85%

**输出**：
- 异常日志列表
- 故障类型标签
- 日志模板和频次统计

#### 1.3 链路异常检测
**输入**：
- 分布式调用链路数据（Jaeger Span）
- 关键指标：响应时间、错误率、调用量

**处理逻辑**：
- 检测慢查询（P99延迟 > 阈值）
- 检测错误激增（错误率 > 5%）
- 服务依赖图分析（上下游影响）

**输出**：
- 慢查询Span列表
- 错误链路火焰图
- 瓶颈服务定位

---

### 2. 故障诊断（Diagnosis）

#### 2.1 RAG知识库检索
**知识库来源**：
- 历史工单（>1000条）
- SOP标准操作文档
- 常见故障案例库（人工整理200+条）

**处理流程**：
```
用户输入错误日志/告警
      ↓
BGE-M3向量化（1024维向量）
      ↓
Milvus向量库检索Top-10相似案例
      ↓
BM25混合检索（稀疏向量）
      ↓
Reranker二次精排（Top-3）
      ↓
返回最相似的历史案例
```

**技术细节**：
- 向量模型：BGE-M3（中文效果SOTA）
- 向量库：Milvus（支持百万级向量秒级检索）
- 文档切片：RecursiveCharacterTextSplitter（500字/块，overlap 50字）
- 检索策略：混合检索（稠密向量 + BM25稀疏向量）

#### 2.2 大模型生成诊断
**LLM选型**：Qwen2.5-14B-Instruct
- 理由：中文能力强、支持128K长上下文、开源可私有化
- 部署方式：本地部署（vLLM加速，8卡A100或量化单卡）

**Prompt模板**：
```
你是AIOps运维专家。根据以下信息分析故障：

【当前故障】
{error_log}

【历史相似案例Top-3】
{retrieved_cases}

【任务】
请以JSON格式输出：
{
  "diagnosis": "故障诊断（一句话概括）",
  "root_cause": "根本原因分析（深入技术细节）",
  "solution": "解决方案（分步骤，可执行）",
  "confidence": 0.85
}
```

**输出要求**：
- 诊断结果：简洁明了，非技术人员也能理解
- 根本原因：深入技术层面，包含调用链路、配置项、资源瓶颈等
- 解决方案：分步骤、可执行的命令或配置修改
- 置信度：0-1之间，基于相似案例相似度和模型logits计算

#### 2.3 根因定位
**服务依赖图分析**：
- 存储：Neo4j图数据库
- 关系类型：DEPENDS_ON（依赖）、CALLS（调用）
- 推理算法：随机游走 + PageRank

**因果推断**：
- 时间窗口关联：故障前5分钟的事件（配置变更、发布、流量突增）
- 相关性分析：Pearson相关系数 > 0.8 的指标

**输出**：
- 根因服务节点
- 影响范围（下游服务列表）
- 时间线（事件序列）

---

### 3. 自动化修复（Remediation）

#### 3.1 修复策略
**低风险操作（自动执行）**：
- 重启服务（非核心服务）
- 清理日志/临时文件（磁盘>85%）
- K8s Pod重启（Liveness Probe失败）
- HPA自动扩容（CPU>80%）

**高风险操作（需审批）**：
- 重启数据库
- 回滚配置
- 切换流量（灰度/全量）
- 数据库表结构变更

#### 3.2 执行工具
**Ansible Playbook**：
- 预定义20+个常用操作
- 示例Playbook：
  - `restart_service.yml`：重启指定服务
  - `clean_logs.yml`：清理7天前日志
  - `scale_k8s.yml`：K8s Deployment扩容

**审批流**：
- 低风险：自动执行 + 企业微信/钉钉通知
- 高风险：发起审批工单 → Leader确认 → 执行 → 结果反馈

#### 3.3 执行监控
**实时监控执行状态**：
- 执行中：显示进度条
- 执行成功：验证指标是否恢复
- 执行失败：回滚 + 人工介入

**修复成功率指标**：
- 自动修复覆盖率：60%
- 修复成功率：>90%
- 平均执行时间：<30秒

---

### 4. 告警与通知

#### 4.1 告警渠道
- 企业微信机器人
- 钉钉机器人
- 邮件（高优先级）
- 短信（P0级故障）

#### 4.2 告警内容
```
【故障告警】
服务：order-service
级别：P1
时间：2024-11-19 14:30:25

故障诊断：数据库连接池耗尽
根本原因：慢SQL导致连接未释放
解决方案：
1. 增加连接池大小（maxActive=50→100）
2. 优化慢SQL（添加索引）
3. 调整超时时间（maxWait=10000→20000）

【一键修复】
[执行自动修复] [查看详情] [人工介入]
```

#### 4.3 告警降噪
- 同类告警聚合（5分钟内相同告警只发一次）
- 依赖服务屏蔽（上游故障时屏蔽下游告警）
- 告警优先级：P0（核心服务）> P1（重要服务）> P2（一般服务）

---

### 5. 可视化与复盘

#### 5.1 实时监控大盘（Grafana）
- 实时指标曲线（CPU/内存/QPS/延迟）
- 告警趋势（每小时告警数）
- 修复成功率统计
- Top故障类型排行

#### 5.2 故障复盘页面
**时间线视图**：
```
14:25:00  CPU使用率突增（85%）
14:26:30  慢SQL检测到（2.3s）
14:27:00  数据库连接池告警（48/50）
14:28:00  服务响应超时（>3s）
14:29:00  【诊断完成】根因：慢SQL
14:30:00  【自动修复】添加索引
14:32:00  【故障恢复】指标恢复正常
```

**根因分析**：
- 服务依赖图（可视化）
- 相关指标对比（故障前后）
- 日志截取（关键ERROR）

**修复记录**：
- 执行步骤
- 命令输出
- 验证结果

---

## 🏗️ 技术架构

### 架构图
```
┌─────────────────────────────────────────────────────────┐
│                    数据采集层                            │
├─────────────────────────────────────────────────────────┤
│ Prometheus  │  ELK Stack   │  Jaeger   │  Kafka        │
│ (指标)      │  (日志)       │  (链路)    │  (消息队列)   │
└──────────────────────┬──────────────────────────────────┘
                       ↓
┌─────────────────────────────────────────────────────────┐
│                    实时计算层                            │
├─────────────────────────────────────────────────────────┤
│ Flink流式分析  │  CEP事件关联  │  预聚合                │
└──────────────────────┬──────────────────────────────────┘
                       ↓
┌─────────────────────────────────────────────────────────┐
│                    AI智能层（核心）                       │
├─────────────────────────────────────────────────────────┤
│ 异常检测    │  日志分析   │  RAG检索   │  LLM诊断      │
│ (3-Sigma/   │  (Drain/    │  (BGE-M3/  │  (Qwen2.5-   │
│  LSTM)      │   BERT)     │   Milvus)  │   14B)       │
└──────────────────────┬──────────────────────────────────┘
                       ↓
┌─────────────────────────────────────────────────────────┐
│                    自动化执行层                           │
├─────────────────────────────────────────────────────────┤
│ Ansible    │  K8s API   │  审批流    │  回滚机制       │
└──────────────────────┬──────────────────────────────────┘
                       ↓
┌─────────────────────────────────────────────────────────┐
│                    可视化层                              │
├─────────────────────────────────────────────────────────┤
│ Grafana大盘  │  故障复盘页  │  知识库管理  │  告警中心   │
└─────────────────────────────────────────────────────────┘
```

### 技术选型

| 分层 | 组件 | 技术选型 | 理由 |
|------|------|---------|------|
| **数据采集** | 指标采集 | Prometheus + Telegraf | 云原生标准、社区成熟 |
| | 日志采集 | Filebeat → Kafka → Logstash | 高吞吐、可靠性强 |
| | 链路追踪 | Jaeger | CNCF毕业项目、兼容OpenTracing |
| **实时计算** | 流式处理 | Flink | 低延迟、高吞吐、Exactly-Once语义 |
| | 事件关联 | Flink CEP | 复杂模式匹配、SQL-like语法 |
| **AI智能** | 时序预测 | Prophet / LSTM(PyTorch) | Prophet易用、LSTM准确率高 |
| | 日志解析 | Drain算法 | 无监督、实时、准确率95%+ |
| | 日志分类 | BERT-base-chinese | 中文效果好、迁移学习快 |
| | 向量化 | BGE-M3 | 中文SOTA、多语言、混合检索 |
| | 向量库 | Milvus | 百万级QPS、GPU加速、分布式 |
| | 大模型 | Qwen2.5-14B-Instruct | 中文强、128K上下文、可私有化 |
| | LLM加速 | vLLM | 吞吐量5-10倍提升 |
| **自动化** | 配置管理 | Ansible | 无需agent、YAML配置、幂等性 |
| | 容器编排 | Kubernetes | 云原生标准、自愈能力强 |
| | 图数据库 | Neo4j | 服务依赖图、Cypher查询 |
| **可视化** | 监控大盘 | Grafana | 支持50+数据源、插件丰富 |
| | Web框架 | FastAPI | 异步高性能、自动生成API文档 |

---

## 📊 性能指标要求

### 数据量级
- **日志量**：日均1TB+（500台服务器）
- **指标量**：3000+指标 × 4次/分钟 = 每分钟1.2万条
- **链路量**：日均500万Span
- **向量库**：20万+文档切片 → 30万+向量

### 性能要求
| 指标 | 目标值 | 当前值 |
|------|--------|--------|
| 指标异常检测延迟 | <30秒 | 25秒 |
| 日志异常检测延迟 | <1分钟 | 45秒 |
| RAG检索延迟 | <100ms | 80ms |
| LLM推理延迟（首字） | <500ms | 350ms |
| LLM推理延迟（完整） | <5秒 | 3.5秒 |
| 修复执行时间 | <30秒 | 20秒 |
| **MTTR（故障恢复时间）** | **<10分钟** | **8分钟** |

### 准确率要求
| 指标 | 目标值 | 当前值 |
|------|--------|--------|
| 异常检测召回率 | >95% | 93% |
| 异常检测精确率 | >85% | 82% |
| 日志分类准确率 | >85% | 87% |
| RAG检索相关性（Top-3） | >90% | 91% |
| LLM诊断准确率 | >80% | 78% |
| 自动修复成功率 | >90% | 92% |

---

## 🚀 实施路线

### 第一阶段：MVP快速验证（2周）
**目标**：验证核心流程，覆盖5种基础故障场景

**Week 1**：
- Day 1-2：环境准备（Prometheus/ELK/Jaeger部署）
- Day 3-4：数据接入（Filebeat/Exporter配置）
- Day 5：时序异常检测（3-Sigma + Prophet）

**Week 2**：
- Day 6-7：日志智能分析（Drain解析 + BERT分类）
- Day 8-9：RAG知识库搭建（LangChain + Milvus）
- Day 10：自动化执行（Ansible Playbook × 5个）
- Day 11-12：可视化大盘 + 故障演练

**交付物**：
- 能检测和诊断5种故障（OOM、超时、磁盘满、连接池满、CPU高）
- 准确率>70%，自动修复覆盖率>50%

### 第二阶段：优化迭代（4周）
**目标**：降低误报率，扩展场景，提升准确率到85%+

- Week 3：动态基线 + 连续异常判定（降低误报）
- Week 4：BM25混合检索 + Reranker（提升RAG准确率）
- Week 5：扩展场景到20+种（网络/DB/K8s/安全等）
- Week 6：知识图谱构建（Neo4j服务依赖图）

### 第三阶段：生产上线（4周）
**目标**：全量灰度发布，接入1000+台服务器

- Week 7-8：压测优化（支持日均1TB日志）
- Week 9：灰度发布（10% → 50% → 100%）
- Week 10：监控优化 + 7×24值班

---

## 🐛 已知问题与优化方案

### 问题1：误报率高
**现象**：业务高峰期3-Sigma告警频繁（误报率30%）

**原因**：阈值固定，未考虑业务周期性

**优化方案**：
- 改为动态基线（对比过去7天同时段）
- 连续3次异常才告警
- Prophet预测趋势辅助判断

**效果**：误报率从30% → 8%

### 问题2：大模型幻觉
**现象**：RAG召回文档不准确，LLM瞎编解决方案

**原因**：
- 单一向量检索不够精准
- 文档切片粒度不合理

**优化方案**：
- 加入BM25混合检索（稠密+稀疏向量）
- Reranker二次精排（bge-reranker-v2-m3）
- Prompt要求引用来源ID
- 文档切片优化（500字/块，overlap 50字）

**效果**：准确率从65% → 82%

### 问题3：修复失败回滚慢
**现象**：自动修复失败后，回滚耗时长（>5分钟）

**原因**：
- 未提前备份配置
- 回滚逻辑不完善

**优化方案**：
- 执行前自动备份（Git版本控制）
- 超时自动回滚（3分钟内无响应）
- 增加健康检查（执行后验证指标）

**效果**：回滚时间从5分钟 → 30秒

---

## 📚 参考资料

### 论文
- 《AIOps: Real-World Challenges and Research Innovations》
- 《Drain: An Online Log Parsing Approach with Fixed Depth Tree》
- 《Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks》

### 开源项目
- [Qwen2.5](https://github.com/QwenLM/Qwen2.5)
- [Milvus](https://github.com/milvus-io/milvus)
- [LangChain](https://github.com/langchain-ai/langchain)
- [Drain3](https://github.com/logpai/Drain3)

### 技术博客
- 阿里云AIOps实践
- 美团智能运维平台
- 腾讯SRE体系

---

## 📞 联系方式

- 项目负责人：[你的名字]
- 邮箱：your-email@example.com
- GitHub：https://github.com/YOUR_USERNAME/aiops-rag-demo

---

**文档版本**：v1.0  
**更新时间**：2024-11-19  
**状态**：✅ MVP已完成，优化迭代中
